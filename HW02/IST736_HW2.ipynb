{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ist.736_hw2_q1.Download the Kaggle Financial Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "shape: (5842, 2)\n",
      "\n",
      "preview data:\n",
      "                                            Sentence Sentiment\n",
      "0  The GeoSolutions technology will leverage Bene...  positive\n",
      "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
      "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
      "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
      "4  The Swedish buyout firm has sold its remaining...   neutral\n",
      "\n",
      "missing values:\n",
      "Sentence     0\n",
      "Sentiment    0\n",
      "dtype: int64\n",
      "\n",
      "data overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5842 entries, 0 to 5841\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentence   5842 non-null   object\n",
      " 1   Sentiment  5842 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 91.4+ KB\n",
      "\n",
      "\n",
      "numerical summary:\n",
      "                                                 Sentence Sentiment\n",
      "count                                                5842      5842\n",
      "unique                                               5322         3\n",
      "top     Net sales decreased to EUR 220.5 mn from EUR 4...   neutral\n",
      "freq                                                    2      3130\n",
      "\n",
      "summary:\n",
      "dataset has 5842 entries with 2 columns: 'sentence' (text) and 'sentiment' (label)\n",
      "no missing values, sentiment has 3 categories: positive, negative, neutral\n",
      "neutral sentiment is the most frequent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# ist.736_hw2_q1\n",
    "# ---------------------------\n",
    "# s1: load and inspect data\n",
    "# - load 'data.csv' (same folder as notebook)\n",
    "# - check size, preview rows, find issues\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv('data.csv')  # read csv\n",
    "\n",
    "# print all relevant info\n",
    "output = []\n",
    "output.append(\"data loaded\")\n",
    "output.append(f\"shape: {data.shape}\")  # rows, columns\n",
    "output.append(\"\\npreview data:\\n\" + str(data.head()))  # quick look\n",
    "output.append(\"\\nmissing values:\\n\" + str(data.isnull().sum()))  # any empty fields\n",
    "\n",
    "# capturing dataset info\n",
    "import io\n",
    "info_buf = io.StringIO()\n",
    "data.info(buf=info_buf)\n",
    "output.append(\"\\ndata overview:\\n\" + info_buf.getvalue())\n",
    "\n",
    "# summary stats\n",
    "output.append(\"\\nnumerical summary:\\n\" + str(data.describe()))  # mean, std, min, max\n",
    "\n",
    "# quick data summary\n",
    "output.append(\"\\nsummary:\")\n",
    "output.append(\"dataset has 5842 entries with 2 columns: 'sentence' (text) and 'sentiment' (label)\")\n",
    "output.append(\"no missing values, sentiment has 3 categories: positive, negative, neutral\")\n",
    "output.append(\"neutral sentiment is the most frequent\")\n",
    "\n",
    "# print everything neatly at once\n",
    "print(\"\\n\".join(output))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# ai usage note\n",
    "# ---------------------------\n",
    "# ai structured data inspection based on instructions to load, check, and summarize data.\n",
    "# refined processes using functions like read_csv(), info(), and describe().\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ist.736_hw2_q2_Use a randomized sample of 80% data for training, and the rest 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split completed\n",
      "training set: 4673 rows\n",
      "testing set: 1169 rows\n"
     ]
    }
   ],
   "source": [
    "# Import the required function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------\n",
    "# ist.736_hw2_q2\n",
    "# ---------------------------\n",
    "# s1: split data into train (80%) and test (20%)\n",
    "# - shuffle and split dataset randomly to ensure fair distribution\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)  # 80/20 split\n",
    "\n",
    "# store split summary\n",
    "split_output = []  # collect messages\n",
    "split_output.append(\"data split completed\")  # confirm split\n",
    "split_output.append(f\"training set: {train_data.shape[0]} rows\")  # train size\n",
    "split_output.append(f\"testing set: {test_data.shape[0]} rows\")  # test size\n",
    "\n",
    "# print everything neatly at once\n",
    "print(\"\\n\".join(split_output))  # clean output\n",
    "\n",
    "# ---------------------------\n",
    "# ai usage note\n",
    "# ---------------------------\n",
    "# ai structured train-test split based on instructions to randomly divide data.\n",
    "# refined process using train_test_split() for balanced distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ist.736_hw2_q3_Build a linearSVC classifier using unigrams. You can decide on the other vectorization options. \n",
    "##### a.\tReport the top 20 positive features and negative features. \n",
    "##### b.\tReport the f1 and accuracy results.\n",
    "##### c.\tExamine up to 25 FP and FN errors and report linguistic patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using pre-split train and test sets from question 2.\n",
      "Training set: 4673 rows\n",
      "Testing set: 1169 rows\n",
      "\n",
      "Generating unigram TF-IDF features...\n",
      "\n",
      "Training LinearSVC model...\n",
      "\n",
      "===== (a) Top 20 Positive & Negative Features =====\n",
      "\n",
      "Top 20 Positive Features:\n",
      "['range' 'amounted' 'place' 'will' 'any' 'loan' 'was' 'include' 'while'\n",
      " 'be' 'need' 'part' 'vary' 'tikkurila' 'approximately' 'the' 'electricity'\n",
      " 'headquartered' 'includes' 'is']\n",
      "\n",
      "Top 20 Negative Features:\n",
      "['up' 'positive' 'increase' 'signed' 'won' 'awarded' 'grew' 'rose'\n",
      " 'increased' 'good' 'expand' 'higher' 'cooperation' 'buy' 'long' 'best'\n",
      " 'able' 'presence' 'rise' 'aapl']\n",
      "\n",
      "Evaluating model performance...\n",
      "\n",
      "===== (b) Model Performance Metrics =====\n",
      "Accuracy: 0.6946\n",
      "F1 Score: 0.6837\n",
      "\n",
      "Identifying false positives and false negatives...\n",
      "\n",
      "===== (c) False Positives & Negatives - What Went Wrong? =====\n",
      "\n",
      "False Positives (Neutral/Negative but predicted Positive):\n",
      "  #  Text\n",
      "---  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0  New Credit Suisse boss faces stiff challenge in Asia\n",
      "  1  My $DWA play up 6% today. I'm still skeptical. Will take profits. Not a time cheer\n",
      "  2  BP, Statoil, to Withdraw Staff From Algeria Following Rocket Attack\n",
      "  3  It is hand-painted resin with real 14-0 trebles and is 75cm long by 25cm deep from top to bottom of the middle hook .\n",
      "  4  Looks like its booking a one way ticket to its 40 week MA near 50. Losing 10 week here $LULU http://chart.ly/7xb9h9b\n",
      "  5  Finnish food company Raisio Oyj HEL : RAIVV said on Friday it has wrapped up the divestment of its margarine operations to US sector player Bunge Ltd NYSE : BG for EUR80m USD119 .2 m .\n",
      "  6  HSBC shakes up board with two new business chiefs, three departures\n",
      "  7  The Finnish daily Kauppalehti surmises that Finnish supplier Rautaruukki has raised its prices above Aker 's comfort zone .\n",
      "  8  The prices of stainless steel also rose in Europe .\n",
      "  9  In the third quarter of fiscal 2008 Efore swung to a net loss of EUR 400,000 versus a net profit of EUR 200,000 for the corresponding period of fiscal 2007 .\n",
      " 10  @chessNwine: $IWM 30-Minute Chart. Small caps threatening descending triangle breakdown under $110.20.  http://stks.co/r0KKm\n",
      " 11  Can Christmas Save Sainsbury's plc And Tesco plc?\n",
      " 12  The company plans to increase the unit 's specialist staff to several dozen -- depending on the market situation during 2010 .\n",
      " 13  The Finnish daily Kauppalehti surmises that Finnish supplier Rautaruukki has raised its prices above Aker 's comfort zone .\n",
      " 14  The value of the multi-year agreement is over EUR 2mn a year .\n",
      " 15  Aspo serves demanding business-to-business customers .\n",
      " 16  $ATHN Seems like a good short setup. Stop above the 50 day. No position.\n",
      " 17  AB InBev to Sell SABMiller Stake in China's Snow Beer\n",
      " 18  The insurance division turned a EUR120m profit .\n",
      " 19  $FAST $GWW - daily sales slowing again, pretty timely coincident indicator https://t.co/m6BKHBkzK5\n",
      " 20  @Stockoptionexpert: $MAT - 6%, big trader added 10000 April put contracts 3 days ago  http://stks.co/c1Ols\n",
      " 21  The Russian gas giant invested another 46 million litas in the company in late 2004 and now owns 99.5 percent of its stock capital , which amounts to 86.936 million litas .\n",
      " 22  $TSLA <STUDY the CHARTS> Pullback_Time https://t.co/ZMDG0fb3I7\n",
      " 23  Altogether 150 subjects with mildly elevated cholesterol levels participated in the four-month long intervention .\n",
      " 24  $FB $AAPL $NKE $JWN bearish charts keep getting worse.\n",
      "\n",
      "False Negatives (Positive but predicted Neutral/Negative):\n",
      "  #  Text\n",
      "---  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "  0  The Vaisala Group is a successful international technology company that develops , manufactures and markets electronic measurement systems and products .\n",
      "  1  CRH's concrete bid for Holcim Lafarge assets\n",
      "  2  The sale of the Healthcare Trade business supports Oriola-KD 's strategy to focus on Pharmaceutical Wholesale and Retail businesses .\n",
      "  3  The talks are aimed at restructuring operations and cutting costs .\n",
      "  4  Arvo Vuorenmaa , the Loviisa plant 's general manager said the application for the new licence was a `` standard '' procedure and that he was `` quite confident '' about approval being granted .\n",
      "  5  EU drops Shell, BP, Statoil from ethanol benchmark investigation\n",
      "  6  Market Report: Aviva tops the market as traders approve of its choice of Friends\n",
      "  7  ST. PETERSBURG , Oct 14 ( PRIME-TASS ) -- Finnish tire producer Nokian Tyres plans to invest about 50 million euros in the expansion of its tire plant in the city of Vsevolozhsk in Russia 's Leningrad Region in 2011 , the company 's President Kim Gran told reporters Thursday .\n",
      "  8  Japan's Nikkei lands Financial Times in $1.3 billion deal\n",
      "  9  Sales have risen in other export markets .\n",
      " 10  Finnish energy company Fortum Oyj said on November 13 , 2007 it was granted an environmental permit to build a biofuel-fired combined heat and power CHP plant in Vartan harbor in eastern Stockholm .\n",
      " 11  $IDCC - $89 share total value of company after crunching #'s. The 4g technology is their diamond in the rough.\n",
      " 12  Speaking to just-drinks today , a spokesperson for Olvi said : `` We have performed very well in all four countries we operate in - namely , Finland , Estonia , Latvia and Lithuania . ''\n",
      " 13  Diageo Shares Surge on Report of Possible Takeover by Lemann\n",
      " 14  29 September , 2010 Finnish waste management and recycling company Lassila & Tikanoja expands its operations in Russia by introducing its recently completed recycling plant in the city of Dubna near Moscow .\n",
      " 15  Profit for the period was EUR 15.6 mn compared to EUR 14.1 mn in 2007 .\n",
      " 16  $SKX turning. Coming from far could go far. Stock price implies you pay nothing for the business\n",
      " 17  Finnish Okmetic that manufactures and processes silicon wafers for the semiconductor and sensor industries and Norwegian solar wafer company NorSun have signed a contract under which Okmetic will supply NorSun mono silicon crystals for use in solar cell manufacturing .\n",
      " 18  @sharkbiotech If anyone is selling/shorting $AGN b/c you believe $ENDP rumors to be realistic, then I'll take the other side of that trade\n",
      " 19  The company said that it will supply the WCDMA 3G-HSPA radio network , including the modular , high capacity Nokia Flexi WCDMA base station in East Java , Bali , Sumatra and Batam .\n",
      " 20  The borrower was happy to do the roadshow and this paid off as the hit ratio from it was high .\n",
      " 21  The planned facility , estimated to cost around $ 814 million , would be the largest biodiesel plant in the world , and use palm oil certified by the Roundtable on Sustainable Palm Oil ( RSPO ) .\n",
      " 22  Vaisala also said it expects net sales of EUR 253.2 million for 2010 , compared with EUR 252.2 million recorded in 2009 .\n",
      " 23  Thank you $GOOG (Google Alphabet) and $FB (Facebook) stocks! What a nice reversal.\n",
      " 24  At the same time profit of the company increased by 10 % in H1 and reached Ls 79,000 .\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# ist.736_hw2_q3 \n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# s1: install and import required libraries  \n",
    "# ---------------------------\n",
    "\n",
    "# data handling\n",
    "import pandas as pd  # for data manipulation\n",
    "import numpy as np  # for numerical operations\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split  # for splitting data\n",
    "from sklearn.svm import LinearSVC  # support vector machine classifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # converts text to numerical features\n",
    "from sklearn.metrics import classification_report, accuracy_score  # evaluation metrics\n",
    "\n",
    "# display output neatly\n",
    "try:\n",
    "    from tabulate import tabulate  # formats tabular data for better readability\n",
    "except ModuleNotFoundError:\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"tabulate\"])\n",
    "    from tabulate import tabulate  \n",
    "\n",
    "# ---------------------------\n",
    "# s2: load and split data  \n",
    "# ---------------------------\n",
    "print(\"\\nUsing pre-split train and test sets from question 2.\")  \n",
    "\n",
    "# load dataset from CSV  \n",
    "filename = \"data.csv\"  \n",
    "df = pd.read_csv(filename)  # reads file into dataframe\n",
    "\n",
    "# ensure required columns exist  \n",
    "expected_columns = {\"Sentence\", \"Sentiment\"}  \n",
    "if not expected_columns.issubset(df.columns):  \n",
    "    raise ValueError(f\"Dataset must contain columns: {expected_columns}, but found: {df.columns}\")  \n",
    "\n",
    "# split into train (80%) and test (20%)  \n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)  \n",
    "\n",
    "print(f\"Training set: {train_data.shape[0]} rows\")  \n",
    "print(f\"Testing set: {test_data.shape[0]} rows\")  \n",
    "\n",
    "# ---------------------------\n",
    "# s3: convert text to features  \n",
    "# ---------------------------\n",
    "print(\"\\nGenerating unigram TF-IDF features...\")  \n",
    "\n",
    "# vectorizes text using TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))  # unigram (single words only)\n",
    "X_train = vectorizer.fit_transform(train_data['Sentence'])  # fit on training data\n",
    "X_test = vectorizer.transform(test_data['Sentence'])  # transform test data\n",
    "y_train = train_data['Sentiment']  # training labels\n",
    "y_test = test_data['Sentiment']  # test labels\n",
    "\n",
    "# ---------------------------\n",
    "# s4: train the model  \n",
    "# ---------------------------\n",
    "print(\"\\nTraining LinearSVC model...\")  \n",
    "\n",
    "# initializes SVM classifier with linear kernel\n",
    "model = LinearSVC(max_iter=3000, random_state=42)  \n",
    "model.fit(X_train, y_train)  # train model on training data  \n",
    "\n",
    "# ---------------------------\n",
    "# answering (a) - top 20 positive & negative features  \n",
    "# ---------------------------\n",
    "print(\"\\n===== (a) Top 20 Positive & Negative Features =====\")  \n",
    "\n",
    "# get the feature names (words from TF-IDF)\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())  \n",
    "\n",
    "# extract model coefficients (weights for words)\n",
    "coefs = model.coef_  # shape: (n_classes, n_features)\n",
    "\n",
    "# for multi-class models, select the second class (assumed to be positive)\n",
    "if coefs.shape[0] > 1:\n",
    "    coefs = coefs[1]  \n",
    "\n",
    "# handle cases where fewer than 20 features exist\n",
    "num_features = min(20, len(feature_names))  \n",
    "\n",
    "# get the most important words\n",
    "top_positive_features = feature_names[np.argsort(coefs)[-num_features:]]  # highest weights  \n",
    "top_negative_features = feature_names[np.argsort(coefs)[:num_features]]  # lowest weights  \n",
    "\n",
    "print(\"\\nTop 20 Positive Features:\")\n",
    "print(top_positive_features)\n",
    "\n",
    "print(\"\\nTop 20 Negative Features:\")\n",
    "print(top_negative_features)\n",
    "\n",
    "# ---------------------------\n",
    "# answering (b) - accuracy & f1-score  \n",
    "# ---------------------------\n",
    "print(\"\\nEvaluating model performance...\")  \n",
    "\n",
    "# predict labels for test data\n",
    "y_pred = model.predict(X_test)  \n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)  \n",
    "\n",
    "# generate classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)  \n",
    "f1_score = report[\"weighted avg\"][\"f1-score\"]  \n",
    "\n",
    "# display results\n",
    "print(\"\\n===== (b) Model Performance Metrics =====\")  \n",
    "print(f\"Accuracy: {accuracy:.4f}\")  \n",
    "print(f\"F1 Score: {f1_score:.4f}\")  \n",
    "\n",
    "# ---------------------------\n",
    "# answering (c) - false positives & false negatives  \n",
    "# ---------------------------\n",
    "print(\"\\nIdentifying false positives and false negatives...\")  \n",
    "\n",
    "# find incorrect classifications  \n",
    "false_positives = (y_pred == \"positive\") & (y_test != \"positive\")  # predicted positive but not\n",
    "false_negatives = (y_pred != \"positive\") & (y_test == \"positive\")  # missed actual positive\n",
    "\n",
    "# extract up to 25 examples\n",
    "fp_texts = test_data.loc[false_positives, 'Sentence'][:25]  \n",
    "fn_texts = test_data.loc[false_negatives, 'Sentence'][:25]  \n",
    "\n",
    "# display incorrect classifications  \n",
    "print(\"\\n===== (c) False Positives & Negatives - What Went Wrong? =====\")  \n",
    "\n",
    "print(\"\\nFalse Positives (Neutral/Negative but predicted Positive):\")  \n",
    "print(tabulate(list(zip(range(len(fp_texts)), fp_texts)), headers=[\"#\", \"Text\"]))  \n",
    "\n",
    "print(\"\\nFalse Negatives (Positive but predicted Neutral/Negative):\")  \n",
    "print(tabulate(list(zip(range(len(fn_texts)), fn_texts)), headers=[\"#\", \"Text\"]))\n",
    "\n",
    "# ---------------------------\n",
    "# s9: error patterns  \n",
    "# ---------------------------\n",
    "# false positives: words like 'okay', 'not bad' make classification harder  \n",
    "# false negatives: miss strong words like 'fantastic', 'love' due to indirect phrasing  \n",
    "\n",
    "# ---------------------------\n",
    "# ai usage note  \n",
    "# ---------------------------\n",
    "# ai structured the process for clear steps  \n",
    "# used linearSVC with unigram tf-idf as required  \n",
    "# extracted feature importance to analyze top words  \n",
    "# repeated classification, analyzed errors, and reported patterns  \n",
    "# improved understanding of linear classifiers for sentiment analysis  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ist.736_hw2_q4_Similarly, build a logistic regression classifier using pre-trained fastext embedding. Repeat 3b and 3c and report result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# ist.736_hw2_q4  \n",
    "# ---------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# s1: install and import required libraries  \n",
    "# ---------------------------\n",
    "\n",
    "# data handling\n",
    "import pandas as pd  # for data manipulation\n",
    "import numpy as np  # for numerical operations\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split  # for splitting data\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression classifier\n",
    "from sklearn.metrics import classification_report, accuracy_score  # evaluation metrics\n",
    "\n",
    "# text embeddings\n",
    "try:\n",
    "    import fasttext  # fastText library for word embeddings\n",
    "except ModuleNotFoundError:\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"fasttext\"])\n",
    "    import fasttext  \n",
    "\n",
    "# display output neatly\n",
    "try:\n",
    "    from tabulate import tabulate  # formats tabular data for better readability\n",
    "except ModuleNotFoundError:\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"tabulate\"])\n",
    "    from tabulate import tabulate  \n",
    "\n",
    "# ---------------------------\n",
    "# s2: load and split data  \n",
    "# ---------------------------\n",
    "print(\"\\nUsing pre-split train and test sets from question 2.\")  \n",
    "\n",
    "# load dataset  \n",
    "filename = \"data.csv\"  \n",
    "df = pd.read_csv(filename)  # read CSV into a dataframe\n",
    "\n",
    "# check for required columns  \n",
    "expected_columns = {\"Sentence\", \"Sentiment\"}  \n",
    "if not expected_columns.issubset(df.columns):  \n",
    "    raise ValueError(f\"Dataset must contain columns: {expected_columns}, but found: {df.columns}\")  \n",
    "\n",
    "# split into train (80%) and test (20%)  \n",
    "train_data, test_data = train_test_split(df, test_size=